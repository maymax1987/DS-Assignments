{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb47c29-dc8e-444b-9dda-e772251612c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af2aa74-ebd0-4c98-8424-fd05d9fa94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155e89ae-a7e4-436e-b72e-c9150ab8c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed4e093-9c76-4868-9aa3-14fdd05565aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98118bff-a0e8-4e4c-839f-05f9cdb00c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a9dc66-3f1a-4c0a-8c2b-ea5aee795e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Alphabets_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0c9737-dc2a-407d-95ba-b15713b46b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c6a19d-b9d4-474a-9d62-78f86f492bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8eef748-8a87-4f21-800c-940f2491c86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb270e9-f800-4d55-a2de-020d2851b523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72836ce0-e280-4a7f-868d-3e2fe043a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['letter'] = label_encoder.fit_transform(df['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08773071-6f50-41e5-8a74-ee4c81d6977f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          19     2     8      3       5      1     8    13      0      6   \n",
       "1           8     5    12      3       7      2    10     5      5      4   \n",
       "2           3     4    11      6       8      6    10     6      2      6   \n",
       "3          13     7    11      6       6      3     5     9      4      6   \n",
       "4           6     2     1      3       1      1     8     6      6      6   \n",
       "...       ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995       3     2     2      3       3      2     7     7      7      6   \n",
       "19996       2     7    10      8       8      4     4     8      6      9   \n",
       "19997      19     6     9      6       7      5     6    11      3      7   \n",
       "19998      18     2     3      4       2      1     8     7      2      6   \n",
       "19999       0     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcda02d7-1898-4781-aef1-9a7ba6565e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['letter'])  # Features\n",
    "y = df['letter'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048c9ec3-29f9-42d2-831c-7dead88334ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac7295c-ec48-4324-a8c0-80d582716206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0576983 ,  0.29187713, -1.05327668, ..., -0.21908163,\n",
       "        -1.4381527 ,  0.12291107],\n",
       "       [ 0.51038497,  1.5023577 , -1.05327668, ..., -0.21908163,\n",
       "         0.12008142,  1.35944092],\n",
       "       [-0.01230945,  1.19973756,  0.43590966, ..., -0.8656262 ,\n",
       "        -0.26947711,  0.74117599],\n",
       "       ...,\n",
       "       [ 1.03307939,  0.59449727,  0.43590966, ...,  2.36709667,\n",
       "        -0.65903564, -2.35014863],\n",
       "       [-1.0576983 , -1.22122359, -0.55688123, ...,  0.42746295,\n",
       "         0.50963994,  0.12291107],\n",
       "       [-0.01230945,  0.59449727,  0.43590966, ..., -0.8656262 ,\n",
       "        -0.65903564,  0.12291107]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "253e320d-429f-4e9b-b050-895fe2adedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['letter'])\n",
    "y_encoded = to_categorical(y_encoded, num_classes=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db56c20-bc56-4636-99f5-2e6804edb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85fa4c5c-11a7-4632-9804-bf708e18a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 16)\n",
      "(16000, 16)\n",
      "(4000, 26)\n",
      "(16000, 26)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a2ef658-8358-4e5a-b131-7fcb6b64aac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fc99a07-5e9f-482b-8f7e-cb8a242ea844",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cf6c4-a51e-4e30-89ca-56c912ed8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70380653-8fc0-4f31-b6f3-c6b160bb140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b6bc575-ad72-49f8-ad18-b28aa2b56512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Additional hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer (26 units for each alphabet class, using softmax for multiclass classification)\n",
    "model.add(Dense(26, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c0ce185-285f-491e-8c9a-5f06944fcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dd2c72d-fd69-4ebe-b1e2-1e9a17aa152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2770 - loss: 2.6219 - val_accuracy: 0.6750 - val_loss: 1.1731\n",
      "Epoch 2/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 1.0273 - val_accuracy: 0.7659 - val_loss: 0.8442\n",
      "Epoch 3/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.7752 - val_accuracy: 0.7941 - val_loss: 0.7121\n",
      "Epoch 4/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.6529 - val_accuracy: 0.8197 - val_loss: 0.6238\n",
      "Epoch 5/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.5667 - val_accuracy: 0.8409 - val_loss: 0.5547\n",
      "Epoch 6/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.5056 - val_accuracy: 0.8553 - val_loss: 0.5028\n",
      "Epoch 7/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.4497 - val_accuracy: 0.8650 - val_loss: 0.4662\n",
      "Epoch 8/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.4202 - val_accuracy: 0.8775 - val_loss: 0.4280\n",
      "Epoch 9/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3845 - val_accuracy: 0.8825 - val_loss: 0.4007\n",
      "Epoch 10/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.3516 - val_accuracy: 0.8859 - val_loss: 0.3877\n",
      "Epoch 11/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.3288 - val_accuracy: 0.8906 - val_loss: 0.3588\n",
      "Epoch 12/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.3067 - val_accuracy: 0.9000 - val_loss: 0.3354\n",
      "Epoch 13/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2862 - val_accuracy: 0.9000 - val_loss: 0.3302\n",
      "Epoch 14/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2699 - val_accuracy: 0.9019 - val_loss: 0.3192\n",
      "Epoch 15/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2550 - val_accuracy: 0.9075 - val_loss: 0.3075\n",
      "Epoch 16/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2546 - val_accuracy: 0.9119 - val_loss: 0.2935\n",
      "Epoch 17/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2366 - val_accuracy: 0.9150 - val_loss: 0.2840\n",
      "Epoch 18/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.2190 - val_accuracy: 0.9125 - val_loss: 0.2833\n",
      "Epoch 19/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.2129 - val_accuracy: 0.9153 - val_loss: 0.2740\n",
      "Epoch 20/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.2023 - val_accuracy: 0.9109 - val_loss: 0.2751\n",
      "Epoch 21/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1976 - val_accuracy: 0.9197 - val_loss: 0.2612\n",
      "Epoch 22/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1935 - val_accuracy: 0.9212 - val_loss: 0.2558\n",
      "Epoch 23/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1872 - val_accuracy: 0.9191 - val_loss: 0.2481\n",
      "Epoch 24/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1738 - val_accuracy: 0.9219 - val_loss: 0.2552\n",
      "Epoch 25/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1717 - val_accuracy: 0.9234 - val_loss: 0.2448\n",
      "Epoch 26/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1688 - val_accuracy: 0.9231 - val_loss: 0.2479\n",
      "Epoch 27/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1596 - val_accuracy: 0.9250 - val_loss: 0.2348\n",
      "Epoch 28/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1501 - val_accuracy: 0.9262 - val_loss: 0.2374\n",
      "Epoch 29/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1500 - val_accuracy: 0.9250 - val_loss: 0.2327\n",
      "Epoch 30/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1458 - val_accuracy: 0.9247 - val_loss: 0.2358\n",
      "Epoch 31/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1430 - val_accuracy: 0.9281 - val_loss: 0.2271\n",
      "Epoch 32/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1373 - val_accuracy: 0.9309 - val_loss: 0.2194\n",
      "Epoch 33/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1221 - val_accuracy: 0.9241 - val_loss: 0.2366\n",
      "Epoch 34/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1273 - val_accuracy: 0.9253 - val_loss: 0.2351\n",
      "Epoch 35/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1229 - val_accuracy: 0.9272 - val_loss: 0.2263\n",
      "Epoch 36/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1227 - val_accuracy: 0.9291 - val_loss: 0.2241\n",
      "Epoch 37/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1127 - val_accuracy: 0.9359 - val_loss: 0.2174\n",
      "Epoch 38/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1196 - val_accuracy: 0.9312 - val_loss: 0.2159\n",
      "Epoch 39/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.1084 - val_accuracy: 0.9291 - val_loss: 0.2118\n",
      "Epoch 40/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.1096 - val_accuracy: 0.9334 - val_loss: 0.2207\n",
      "Epoch 41/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.1071 - val_accuracy: 0.9291 - val_loss: 0.2183\n",
      "Epoch 42/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0997 - val_accuracy: 0.9328 - val_loss: 0.2115\n",
      "Epoch 43/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0978 - val_accuracy: 0.9300 - val_loss: 0.2127\n",
      "Epoch 44/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.0968 - val_accuracy: 0.9331 - val_loss: 0.2135\n",
      "Epoch 45/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0936 - val_accuracy: 0.9272 - val_loss: 0.2150\n",
      "Epoch 46/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.0939 - val_accuracy: 0.9353 - val_loss: 0.2002\n",
      "Epoch 47/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0955 - val_accuracy: 0.9356 - val_loss: 0.2103\n",
      "Epoch 48/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0946 - val_accuracy: 0.9369 - val_loss: 0.2044\n",
      "Epoch 49/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0914 - val_accuracy: 0.9331 - val_loss: 0.2105\n",
      "Epoch 50/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0797 - val_accuracy: 0.9334 - val_loss: 0.2009\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "440b2863-799c-4cb4-ad04-8fcf4aa8af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.2207\n",
      "Test Accuracy: 0.9375\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       149\n",
      "           1       0.92      0.90      0.91       153\n",
      "           2       0.94      0.91      0.93       137\n",
      "           3       0.90      0.95      0.92       156\n",
      "           4       0.93      0.91      0.92       141\n",
      "           5       0.90      0.94      0.92       140\n",
      "           6       0.95      0.94      0.94       160\n",
      "           7       0.84      0.85      0.85       144\n",
      "           8       0.97      0.92      0.95       146\n",
      "           9       0.95      0.97      0.96       149\n",
      "          10       0.89      0.89      0.89       130\n",
      "          11       0.97      0.94      0.95       155\n",
      "          12       0.97      0.98      0.97       168\n",
      "          13       0.96      0.88      0.92       151\n",
      "          14       0.91      0.95      0.93       145\n",
      "          15       0.95      0.93      0.94       173\n",
      "          16       0.99      0.92      0.96       166\n",
      "          17       0.89      0.88      0.88       160\n",
      "          18       0.96      0.96      0.96       171\n",
      "          19       0.96      0.93      0.94       163\n",
      "          20       0.95      0.96      0.96       183\n",
      "          21       0.90      0.96      0.93       158\n",
      "          22       0.96      0.98      0.97       148\n",
      "          23       0.96      0.98      0.97       154\n",
      "          24       0.95      0.99      0.97       168\n",
      "          25       0.93      0.95      0.94       132\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.94      0.94      0.94      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47396602-046b-4008-8cf3-e9f233649277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56f9dbac-1df8-4602-bd3a-5f183c92448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.91 using {'batch_size': 16, 'epochs': 50, 'model__activation': 'relu', 'optimizer': 'rmsprop'}\n",
      "Epoch 1/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3265 - loss: 2.3905\n",
      "Epoch 2/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 1.0041\n",
      "Epoch 3/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.7901\n",
      "Epoch 4/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.6975\n",
      "Epoch 5/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.6166\n",
      "Epoch 6/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.5620\n",
      "Epoch 7/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.5164\n",
      "Epoch 8/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.4683\n",
      "Epoch 9/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.4635\n",
      "Epoch 10/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.4207\n",
      "Epoch 11/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3995\n",
      "Epoch 12/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3905\n",
      "Epoch 13/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.3855\n",
      "Epoch 14/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3597\n",
      "Epoch 15/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.3518\n",
      "Epoch 16/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.3313\n",
      "Epoch 17/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3267\n",
      "Epoch 18/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3201\n",
      "Epoch 19/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.3024\n",
      "Epoch 20/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.2988\n",
      "Epoch 21/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2814\n",
      "Epoch 22/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2917\n",
      "Epoch 23/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2727\n",
      "Epoch 24/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2753\n",
      "Epoch 25/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2634\n",
      "Epoch 26/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2568\n",
      "Epoch 27/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.2478\n",
      "Epoch 28/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2580\n",
      "Epoch 29/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2503\n",
      "Epoch 30/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2416\n",
      "Epoch 31/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2461\n",
      "Epoch 32/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2271\n",
      "Epoch 33/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2332\n",
      "Epoch 34/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2349\n",
      "Epoch 35/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2209\n",
      "Epoch 36/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2223\n",
      "Epoch 37/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2237\n",
      "Epoch 38/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2205\n",
      "Epoch 39/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.2137\n",
      "Epoch 40/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9338 - loss: 0.2078\n",
      "Epoch 41/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1989\n",
      "Epoch 42/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.2112\n",
      "Epoch 43/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.2012\n",
      "Epoch 44/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.1981\n",
      "Epoch 45/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.2024\n",
      "Epoch 46/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.2013\n",
      "Epoch 47/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1984\n",
      "Epoch 48/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1938\n",
      "Epoch 49/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.2066\n",
      "Epoch 50/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2820\n",
      "Test Accuracy with Best Parameters: 0.9147499799728394\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       0.94      0.85      0.89       153\n",
      "           2       0.94      0.87      0.90       137\n",
      "           3       0.86      0.92      0.89       156\n",
      "           4       0.88      0.88      0.88       141\n",
      "           5       0.91      0.89      0.90       140\n",
      "           6       0.90      0.88      0.89       160\n",
      "           7       0.82      0.77      0.80       144\n",
      "           8       0.92      0.92      0.92       146\n",
      "           9       0.91      0.93      0.92       149\n",
      "          10       0.81      0.92      0.86       130\n",
      "          11       0.83      0.97      0.89       155\n",
      "          12       0.93      0.98      0.95       168\n",
      "          13       0.98      0.91      0.95       151\n",
      "          14       0.89      0.94      0.92       145\n",
      "          15       0.99      0.90      0.94       173\n",
      "          16       0.91      0.95      0.93       166\n",
      "          17       0.89      0.84      0.86       160\n",
      "          18       0.93      0.92      0.93       171\n",
      "          19       0.97      0.89      0.93       163\n",
      "          20       0.94      0.96      0.95       183\n",
      "          21       0.95      0.94      0.95       158\n",
      "          22       0.96      0.96      0.96       148\n",
      "          23       0.94      0.90      0.92       154\n",
      "          24       0.93      0.97      0.95       168\n",
      "          25       0.95      0.93      0.94       132\n",
      "\n",
      "    accuracy                           0.91      4000\n",
      "   macro avg       0.91      0.91      0.91      4000\n",
      "weighted avg       0.92      0.91      0.91      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam', neurons=32, activation='relu'): # Include activation as an argument\n",
    "    model = Sequential()\n",
    "    # Input layer and hidden layers\n",
    "    model.add(Dense(neurons, input_shape=(X_train.shape[1],), activation=activation)) # Use activation here\n",
    "    model.add(Dense(neurons, activation=activation)) # Use activation here\n",
    "    # Output layer (26 classes for alphabets, softmax for multiclass classification)\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Model with KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the Hyperparameter Grid (Remove 'activation' from here)\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50],\n",
    "    'optimizer': ['rmsprop'],\n",
    "    # 'model__neurons': [32, 64, 128], # Pass neurons as 'model__neurons'\n",
    "    'model__activation': ['relu'] # Pass activation as 'model__activation'\n",
    "}\n",
    "\n",
    "# Set Up and Run Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Display the Best Score and Hyperparameters\n",
    "print(\"Best Accuracy: {:.2f} using {}\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Train Final Model Using Best Hyperparameters\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Rebuild the model with best parameters\n",
    "final_model = create_model(\n",
    "    optimizer=best_params['optimizer'],\n",
    "     # Access neurons with 'model__neurons'\n",
    "    activation=best_params['model__activation'] # Access activation with 'model__activation'\n",
    ")\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "final_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
    "\n",
    "# Evaluate the Model on the Test Data\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy with Best Parameters:\", test_accuracy)\n",
    "\n",
    "# Generate a Classification Report\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c536c3b3-256f-4875-93fb-e2ec62a5549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alphabet\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3491 - loss: 2.3659\n",
      "Epoch 2/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.9989\n",
      "Epoch 3/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.8024\n",
      "Epoch 4/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.6959\n",
      "Epoch 5/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.6056\n",
      "Epoch 6/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5438\n",
      "Epoch 7/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.5064\n",
      "Epoch 8/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.4743\n",
      "Epoch 9/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.4431\n",
      "Epoch 10/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.4146\n",
      "Epoch 11/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.4052\n",
      "Epoch 12/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.3728\n",
      "Epoch 13/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3634\n",
      "Epoch 14/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.3376\n",
      "Epoch 15/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3254\n",
      "Epoch 16/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.3199\n",
      "Epoch 17/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.3118\n",
      "Epoch 18/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.3131\n",
      "Epoch 19/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.3055\n",
      "Epoch 20/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2948\n",
      "Epoch 21/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2886\n",
      "Epoch 22/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2848\n",
      "Epoch 23/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2680\n",
      "Epoch 24/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2688\n",
      "Epoch 25/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2667\n",
      "Epoch 26/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2690\n",
      "Epoch 27/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2611\n",
      "Epoch 28/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2553\n",
      "Epoch 29/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2592\n",
      "Epoch 30/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2516\n",
      "Epoch 31/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2492\n",
      "Epoch 32/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2427\n",
      "Epoch 33/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2399\n",
      "Epoch 34/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2282\n",
      "Epoch 35/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2379\n",
      "Epoch 36/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2248\n",
      "Epoch 37/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2201\n",
      "Epoch 38/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2270\n",
      "Epoch 39/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2167\n",
      "Epoch 40/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.2166\n",
      "Epoch 41/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2200\n",
      "Epoch 42/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2295\n",
      "Epoch 43/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.2096\n",
      "Epoch 44/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2090\n",
      "Epoch 45/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2058\n",
      "Epoch 46/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.2036\n",
      "Epoch 47/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.2044\n",
      "Epoch 48/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9339 - loss: 0.2047\n",
      "Epoch 49/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.2138\n",
      "Epoch 50/50\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.1982\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.3114\n",
      "Test Accuracy with Best Parameters: 0.9162499904632568\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       149\n",
      "           1       0.90      0.90      0.90       153\n",
      "           2       0.97      0.91      0.94       137\n",
      "           3       0.92      0.90      0.91       156\n",
      "           4       0.90      0.93      0.92       141\n",
      "           5       0.86      0.91      0.89       140\n",
      "           6       0.91      0.89      0.90       160\n",
      "           7       0.83      0.76      0.79       144\n",
      "           8       0.94      0.90      0.92       146\n",
      "           9       0.97      0.92      0.94       149\n",
      "          10       0.94      0.79      0.86       130\n",
      "          11       0.92      0.95      0.94       155\n",
      "          12       0.97      0.92      0.95       168\n",
      "          13       0.92      0.90      0.91       151\n",
      "          14       0.86      0.98      0.91       145\n",
      "          15       0.93      0.91      0.92       173\n",
      "          16       0.99      0.89      0.94       166\n",
      "          17       0.71      0.93      0.80       160\n",
      "          18       0.94      0.92      0.93       171\n",
      "          19       0.95      0.96      0.95       163\n",
      "          20       0.94      0.95      0.94       183\n",
      "          21       0.95      0.92      0.94       158\n",
      "          22       0.94      0.98      0.96       148\n",
      "          23       0.90      0.97      0.94       154\n",
      "          24       0.97      0.89      0.93       168\n",
      "          25       0.95      0.94      0.95       132\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(\n",
    "    optimizer=best_params['optimizer'],\n",
    "     # Access neurons with 'model__neurons'\n",
    "    activation=best_params['model__activation'] # Access activation with 'model__activation'\n",
    ")\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "final_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
    "\n",
    "# Evaluate the Model on the Test Data\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy with Best Parameters:\", test_accuracy)\n",
    "\n",
    "# Generate a Classification Report\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1861df6-e793-4dab-8392-7b788ac82499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea58985-7896-446a-b6b4-4fe868e341b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e97b6-1e23-40ef-95fa-b214e6f6f6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7faaeb-f85e-4342-86a1-27b38989679d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6374b7-0554-44cb-9eea-491527660cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f209c0-0b23-4212-a4e9-dec70c56c556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
